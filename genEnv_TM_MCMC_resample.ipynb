{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import arviz as az\n",
    "import arviz.labels as azl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next time save source code as .py file and import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.Generator(np.random.PCG64(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arviz to use bokeh in a notebook\n",
    "az.style.use(\"arviz-doc\")\n",
    "# Confgure Bokeh as backend\n",
    "az.rcParams[\"plot.backend\"] = \"bokeh\"\n",
    "az.output_notebook()\n",
    "#get bokeh to work in vs code\n",
    "import panel as pn\n",
    "pn.extension(comms=\"vscode\")\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off pymc model\n",
    "def save_pymc_trace( trace=None, xr_data_source=None, filename='pymc_meodel', multi_index_to_reset =None):\n",
    "    if xr_data_source:\n",
    "        if multi_index_to_reset:\n",
    "            print('adding this', xr_data_source.reset_index(multi_index_to_reset))\n",
    "            trace.add_groups({'data_source':xr_data_source.reset_index(multi_index_to_reset)})\n",
    "        else:\n",
    "            trace.add_groups({'data_source':xr_data_source})\n",
    "\n",
    "    trace.to_netcdf(f'{filename}.nc')#to_zarr(filename)#\n",
    "        \n",
    "    #just rerun the model with no observed data\n",
    "    #with open(filename, 'wb') as buff:\n",
    "    #    pickle.dump({'model':model}, buff)\n",
    "# open pymc model and inference object\n",
    "def open_pymc_trace(filename='pymc_meodel'):\n",
    "    idata = az.from_netcdf(f'{filename}.nc')#az.InferenceData.from_zarr(filename)#\n",
    "    \n",
    "    return idata  #data['model'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data\n",
    "\n",
    "def normalization(xarray=None):\n",
    "    xr_x = xarray\n",
    "    revert_min, revert_spread = xr_x.min(), xr_x.max()-xr_x.min()\n",
    "    xr_x = (xr_x - revert_min) / revert_spread\n",
    "    return xr_x, revert_min, revert_spread\n",
    "def revert_normalization(xarray=None, revert_min=None, revert_spread=None):\n",
    "    xr_x = xarray\n",
    "    xr_x = xr_x * revert_spread + revert_min\n",
    "    return xr_x\n",
    "def convert_normalization(xr_old=None, xr_new=None):\n",
    "    if xr_new.lat.values.size > 0:\n",
    "        xr_new['lat_norm'] = (xr_new.lat - xr_old.attrs['sdz_lat_min']) / xr_old.attrs['sdz_lat_spread'] \n",
    "    if xr_new.long.values.size > 0:\n",
    "        xr_new['long_norm'] = (xr_new.long - xr_old.attrs['sdz_long_min']) / xr_old.attrs['sdz_long_spread']\n",
    "\n",
    "xr_traj_env_time['stz_lat'], sdz_min, stz_spread = normalization(xr_traj_env_time.lat)\n",
    "xr_traj_env_time.attrs['sdz_lat_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_lat_spread']  =stz_spread.values\n",
    "xr_traj_env_time['stz_long'], sdz_min, stz_spread = normalization(xr_traj_env_time.long)\n",
    "xr_traj_env_time.attrs['sdz_long_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_long_spread']  =stz_spread.values\n",
    "xr_traj_env_time['stz_alt'], sdz_min, stz_spread = normalization(xr_traj_env_time.alt)\n",
    "xr_traj_env_time.attrs['sdz_alt_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_alt_spread']  =stz_spread.values\n",
    "\n",
    "xr_traj_env_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in the old trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"data.load\"] = \"eager\"\n",
    "idata3 = open_pymc_trace(filename='thermal_pres')\n",
    "idata2 = idata3.copy()\n",
    "xr_traj_env_time= idata2.data_source\n",
    "xr_traj_env_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model with no observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''coords={'alt_lat_long_time':\n",
    "                      np.arange(xr_traj_env_time.sizes['time'], dtype=int)\n",
    "                      }'''\n",
    "with pm.Model() as thermal_pres:\n",
    "    #set coords in here to be mutable\n",
    "    thermal_pres.add_coord('alt_lat_long_time', np.arange(xr_traj_env_time.sizes['time'], dtype=int), mutable=True)\n",
    "    #Temp is in celcius\n",
    "    \n",
    "    Alt_ = pm.MutableData('Altitude_m', xr_traj_env_time.alt.values,# use normal un-normalized data\n",
    "                                          dims='alt_lat_long_time' )\n",
    "    Lat_ = pm.MutableData('Latitude', xr_traj_env_time.stz_lat.values,\n",
    "                                        dims='alt_lat_long_time' )\n",
    "    Long_ = pm.MutableData('Longitude', xr_traj_env_time.stz_long.values,\n",
    "                                          dims='alt_lat_long_time' )\n",
    "    Temp_ = pm.MutableData('Temperature_Samples', xr_traj_env_time.Temperature.values, dims='alt_lat_long_time' )\n",
    "    Pres_ = pm.MutableData('Pressure_Samples', xr_traj_env_time.Pressure.values, dims='alt_lat_long_time' )\n",
    "    #prior on effect on temp (degC) of altitude and lat, long\n",
    "    baseline_temp = pm.Normal('baseline_temp', mu=17, sigma=5)\n",
    "    Alt_effect_temp = pm.Normal('Alt_effect_temp_Km', mu=-6, sigma=0.5)\n",
    "    Lat_effect_temp = pm.Normal('Lat_effect_temp', mu=0, sigma=10/4)\n",
    "    Long_effect_temp = pm.Normal('Long_effect_temp', mu=0, sigma=25/4)\n",
    "    Lat_Long_effect_temp = 0  #pm.Normal('Lat_Long_effect_temp', mu=0, sigma=1)\n",
    "    #prior on temp and pressure\n",
    "    #TODO: PULL FROM DATABASE into a pm.Interpolated...maybe not: need relationship between data spreads?\n",
    "    mu_t = pm.Deterministic('mu_t',\n",
    "                               baseline_temp + \n",
    "                               Alt_effect_temp/1000 * Alt_ + \n",
    "                               Lat_effect_temp * Lat_ + \n",
    "                               Long_effect_temp * Long_ + \n",
    "                               Lat_Long_effect_temp * Lat_ * Long_, \n",
    "                               dims='alt_lat_long_time')\n",
    "\n",
    "    P0 = pm.Normal('P0', mu=1, sigma=.01)*101_325.00 # lat/long influence on ground level temp captured in Temp_0\n",
    "    g0 = 9.80665\n",
    "    M = 0.0289644\n",
    "    R = 8.3144598\n",
    "    # NOTE: Temp_[0] is not the lowest altitude temperature, but the first temperature in the array\n",
    "    Temp_0 = baseline_temp+ Lat_effect_temp * Lat_ + Long_effect_temp * Long_ # account for lat/long influence on ground level temp\n",
    "    mu_p= pm.Deterministic('mu_p',P0 *  ((mu_t+273.15)/(Temp_0+273.15)) ** (-g0 * M / (R * (Alt_effect_temp/1000))), \n",
    "                                 dims='alt_lat_long_time')\n",
    "    #add_barometric_effects = P0 * (T/T0) ** (-g0 * M / (R * L))\n",
    "    #prior on error variation\n",
    "    sigma_t=pm.Exponential('model_error_t', 1/5)\n",
    "    sigma_p=pm.Exponential('model_error_p', 1/500)\n",
    "    #adjusted temp - normal dist error term\n",
    "    # For resample, remove observed argument?\n",
    "    obs_t = pm.Normal('obs_t', mu=mu_t, sigma=sigma_t, dims='alt_lat_long_time')# observed = Temp_, dims='alt_lat_long_time')#\n",
    "    obs_p = pm.Normal('obs_p', mu=mu_p, sigma=sigma_p, dims='alt_lat_long_time')# observed = Pres_, dims='alt_lat_long_time')\n",
    "    \n",
    "pm.model_to_graphviz(thermal_pres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_dic(lat = [100, 100, 100, 100], long = [250, 100, 250, 100], alt = [5, 5, 20000, 20000]):\n",
    "    investigate_lat_long = xr.Dataset(data_vars={\n",
    "    'lat': lat,\n",
    "    'long': long,\n",
    "    'Altitude_m': alt,\n",
    "    'Temperature_Samples': [0, 0, 0,0],\n",
    "    'Pressure_Samples' :[0,0,0,0],\n",
    "    })\n",
    "        \n",
    "    return investigate_lat_long\n",
    "investigate_lat_long = investigate_dic()\n",
    "\n",
    "def make_temp_prediction(investigate_lat_long, trace=idata2):\n",
    "    convert_normalization(xr_old= xr_traj_env_time,xr_new = investigate_lat_long)\n",
    "    new_length = len(investigate_lat_long.Temperature_Samples.values)\n",
    "    new_coord_values = (trace.constant_data.alt_lat_long_time.values.max() +1) + np.arange(new_length)\n",
    "\n",
    "    with thermal_pres:\n",
    "        thermal_pres.set_dim(name='alt_lat_long_time', \n",
    "                         new_length=new_length,\n",
    "                         coord_values=new_coord_values)\n",
    "    \n",
    "    with thermal_pres:\n",
    "    # do-operator\n",
    "        pm.set_data({'Altitude_m': investigate_lat_long.Altitude_m.values,\n",
    "                 'Latitude': investigate_lat_long.lat_norm.values,\n",
    "                 'Longitude': investigate_lat_long.long_norm.values,\n",
    "                 'Temperature_Samples': investigate_lat_long.Temperature_Samples.values,\n",
    "                 'Pressure_Samples' : investigate_lat_long.Pressure_Samples.values,\n",
    "                 })\n",
    "    \n",
    "    # sample from this out of sample posterior predictive distribution\n",
    "        counterfactual = pm.sample_posterior_predictive(trace, var_names=[\"obs_t\"], predictions=True, progressbar=False)\n",
    "    counterfactual.predictions\n",
    "# make seaborn violin plots along alt_lat_long_time dimension from counterfactual xarray dataset\n",
    "\n",
    "\n",
    "    counterfactual.predictions_constant_data['Longitude'] = revert_normalization( counterfactual.predictions_constant_data.Longitude, \n",
    "                     revert_min=xr_traj_env_time.attrs['sdz_long_min'], \n",
    "                     revert_spread=xr_traj_env_time.attrs['sdz_long_spread'])\n",
    "    counterfactual.predictions_constant_data['Latitude'] = revert_normalization( counterfactual.predictions_constant_data.Latitude,\n",
    "                        revert_min=xr_traj_env_time.attrs['sdz_lat_min'],\n",
    "                        revert_spread=xr_traj_env_time.attrs['sdz_lat_spread'])\n",
    "    counterfactual.predictions=counterfactual.predictions.assign_coords(counterfactual.predictions_constant_data[['Latitude', 'Longitude', 'Altitude_m']])\n",
    "                            \n",
    "    return counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code creates a panel that users can interact with to compare the temperature distributions at two sets of lat, long, and altitude values.  The code uses the hvplot.violin method to create the distributions.\n",
    "pn.extension(sizing_mode = 'stretch_width', template='fast')\n",
    "\n",
    "slider_lat = pn.widgets.IntSlider(name='lat', start=0, end=200, step=1, value=50) # lat slider\n",
    "slider_long = pn.widgets.IntSlider(name='long', start=0, end=200, step=1, value=50) # long slider\n",
    "slider_alt = pn.widgets.IntSlider(name='alt', start=0, end=20_000, step=500, value=500) # alt slider\n",
    "\n",
    "# second set for comparison\n",
    "slider_lat2 = pn.widgets.IntSlider(name='lat', start=0, end=200, step=1, value=50) # lat slider\n",
    "slider_long2 = pn.widgets.IntSlider(name='long', start=0, end=200, step=1, value=50) # long slider\n",
    "slider_alt2 = pn.widgets.IntSlider(name='alt', start=0, end=20_000, step=500, value=500) # alt slider\n",
    "\n",
    "no_slider = [0]\n",
    "\n",
    "#plot_prediction takes in the coordinates of a point, and the number of samples to take from the distribution. It then plots the distribution of temperature at that point.\n",
    "#az.plot_violin\n",
    "def plot_prediction(slider_lat=50, slider_long=50, slider_alt=500, no_slider=[0], var_names=\"obs_t\"):\n",
    "    \n",
    "    return make_temp_prediction(xr.Dataset(data_vars={\n",
    "    'lat': [slider_lat],\n",
    "    'long': [slider_long],\n",
    "    'Altitude_m': [slider_alt],\n",
    "    'Temperature_Samples': no_slider,\n",
    "    'Pressure_Samples' :no_slider,\n",
    "    })\n",
    "    ).predictions.swap_dims({'alt_lat_long_time':'Altitude_m'}).hvplot.violin(y='obs_t',ylabel='Temperature (degC)',\n",
    "                 legend=False, title=f'Temperature Distribution at {slider_lat} lat, {slider_long} long, {slider_alt} alt',\n",
    "                 width=500, height=500, padding=0.4, shared_axes=True)\n",
    "\n",
    "def plot_prediction2(slider_lat=50, slider_long=50, slider_alt=500,\n",
    "                     slider_lat2 = slider_lat2, slider_long2= slider_long2, slider_alt2=slider_alt2,\n",
    "                       no_slider=[0], var_names=\"obs_t\"):\n",
    "    both = plot_prediction(slider_lat=slider_lat, \n",
    "                           slider_long=slider_long, \n",
    "                           slider_alt=slider_alt) + plot_prediction(slider_lat=slider_lat2,\n",
    "                                                                    slider_long=slider_long2, \n",
    "                                                                    slider_alt=slider_alt2)\n",
    "    return both\n",
    "     \n",
    "    \n",
    "    \n",
    "\n",
    "#pre_plot = plot_prediction()\n",
    "\n",
    "display_pn = pn.bind(plot_prediction2,\n",
    "                     slider_lat=slider_lat, \n",
    "                     slider_long=slider_long, \n",
    "                     slider_alt=slider_alt,\n",
    "                     slider_lat2=slider_lat2, \n",
    "                     slider_long2=slider_long2, \n",
    "                     slider_alt2=slider_alt2)\n",
    "#display_pn2 = pn.bind(plot_prediction,slider_lat=slider_lat2, slider_long=slider_long2, slider_alt=slider_alt2)\n",
    "\n",
    "really_display_pn = pn.Column(pn.Row('##Interactive Temperature Comparison'),\n",
    "                              pn.Row(pn.Column(slider_lat, slider_long, slider_alt),pn.Column(slider_lat2, slider_long2, slider_alt2)),\n",
    "                              pn.Row(display_pn))\n",
    "#sync the y axis of both graphs\n",
    "#really_display_pn[2][0][0].link(really_display_pn[2][1][0], bidirectional=True, links={'ylim':'ylim'}) \n",
    "really_display_pn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
