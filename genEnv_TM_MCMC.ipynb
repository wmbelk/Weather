{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Try out Bayesian update to environmental estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "#%%\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import arviz as az\n",
    "import arviz.labels as azl\n",
    "from hierarchical_normal_belk import hierarchical_normal\n",
    "import itertools\n",
    "#!! conda install -c conda-forge flox\n",
    "import flox\n",
    "from flox.xarray import xarray_reduce # useful in doing multiple coord groupings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.Generator(np.random.PCG64(1234))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 160 #size of grid\n",
    "horz_offest = 10 #offset of grid from 0,0\n",
    "mean_tempC_Km = 6.5/1000 #mean lapse rate\n",
    "max_alt_Km = 13 #max altitude in km\n",
    "#keep lat and long square for ease of matrixing\n",
    "lat = np.arange(horz_offest, size)\n",
    "long = np.arange(0, size - horz_offest)\n",
    "alt = np.arange(0, max_alt_Km)*1000 #in meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR is auto-regressive, MA is moving average; will only use AR \n",
    "def sample_AR_signal(n_samples, corr, mu=0, sigma=1):\n",
    "    assert 0 < corr < 1, \"Auto-correlation must be between 0 and 1\"\n",
    "    burn_samples = 100\n",
    "    n_samples=n_samples+burn_samples\n",
    "\n",
    "    # Find out the offset `c` and the std of the white noise `sigma_e`\n",
    "    # that produce a signal with the desired mean and variance.\n",
    "    # See https://en.wikipedia.org/wiki/Autoregressive_model\n",
    "    # under section \"Example: An AR(1) process\".\n",
    "    c = mu * (1 - corr)\n",
    "    sigma_e = np.sqrt((sigma ** 2) * (1 - corr ** 2))\n",
    "\n",
    "    # Sample the auto-regressive process.\n",
    "    signal = [c + np.random.normal(0, sigma_e)]\n",
    "    for _ in range(1, n_samples):\n",
    "        signal.append(c + corr * signal[-1] + np.random.normal(0, sigma_e))\n",
    "    \n",
    "    return np.array(signal[burn_samples:])\n",
    "\n",
    "def compute_corr_lag_1(signal):\n",
    "    return np.corrcoef(signal[:-1], signal[1:])[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Baseline thermal along latitude\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = .05\n",
    "samp_lat_base = sample_AR_signal(size-horz_offest, 0.5, mu=2, sigma=base_sigma)\n",
    "samp_lat= pd.DataFrame(samp_lat_base)\n",
    "print(compute_corr_lag_1(samp_lat_base), samp_lat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Extend along longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use latitudes as mean for AR signal along longitudes\n",
    "samp = sample_AR_signal(size-horz_offest, 0.75, mu=samp_lat, sigma=base_sigma)\n",
    "samp = pd.DataFrame(samp[:, :, 0])\n",
    "print(compute_corr_lag_1(samp.iloc[:,0]),compute_corr_lag_1(samp.iloc[0,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_temperature_env(samp):\n",
    "    x2, y2 = np.meshgrid(samp.index.values, samp.columns.values)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    axes = plt.axes(projection='3d')\n",
    "    axes.plot_surface(x2, y2,samp.values,cmap=cm.coolwarm,\n",
    "                          linewidth=0, antialiased=False)\n",
    "    axes.set_ylabel('Longitude')\n",
    "    axes.set_xlabel('Latitude')\n",
    "    axes.set_zlabel('Temperature')\n",
    "    # keeps padding between figure elements\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_temperature_env(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Add trend on top of the AR variation -- to baseline thermal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MA\n",
    "lat_inc_slope = 15/100 #deterministic slope of increase in temperature with latitude\n",
    "lat_inc_max = lat_inc_slope *(size-horz_offest) \n",
    "long_inc_mu, long_inc_std = 25/100, .1  #mean and std of increase in temperature with longitude\n",
    "\n",
    "def add_inc_MA(size, horz_offest, sample_AR_signal, samp_lat, lat_inc_max, long_inc_mu, long_inc_std):\n",
    "    lat_inc = np.linspace(0,lat_inc_max, len(samp_lat))\n",
    "    sample_lat_inc = samp_lat[0] + lat_inc\n",
    "    sample_lat_inc = pd.DataFrame(sample_lat_inc)\n",
    "#sample_lat_inc.plot()\n",
    "\n",
    "    samp_inc = sample_AR_signal(size-horz_offest, corr=0.5, mu=sample_lat_inc)\n",
    "    long_inc = stats.norm.rvs(loc=long_inc_mu, scale=long_inc_std, size=(size-horz_offest,size-horz_offest), random_state=None)\n",
    "    long_inc = np.cumsum(long_inc, axis=0)\n",
    "    samp_inc = pd.DataFrame(samp_inc[:, :, 0]+long_inc)\n",
    "    return samp_inc\n",
    "\n",
    "samp_inc = add_inc_MA(size, horz_offest, sample_AR_signal, samp_lat, lat_inc_max, long_inc_mu, long_inc_std)\n",
    "\n",
    "\n",
    "plot_temperature_env(samp_inc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Extend into atmosphere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#allow for inversion by having random lapse rate at diff altitudes\n",
    "def add_altitude_effects(rng, samp_inc, mean_tempC_Km, max_alt_Km):\n",
    "    tempC_Km = rng.normal(loc=mean_tempC_Km, scale=mean_tempC_Km/10, size=max_alt_Km)\n",
    "# Temp at altitude = base temp - tempC_km * altitude\n",
    "    temperature = ( [np.array(samp_inc) \n",
    "                 for _ in np.arange(max_alt_Km)]\n",
    "               -np.broadcast_to(\n",
    "    tempC_Km * np.arange(max_alt_Km)*1000, (size-horz_offest,size-horz_offest,max_alt_Km)\n",
    "    ).T\n",
    ")\n",
    "    temperature = temperature.T\n",
    "    return temperature\n",
    "\n",
    "temp_3D = add_altitude_effects(rng, samp_inc, mean_tempC_Km, max_alt_Km)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xr_temp_3D = xr.DataArray(temp_3D, dims=['lat', 'long', 'alt'], coords={'lat': lat, 'long': long, 'alt': alt})\n",
    "fig = xr_temp_3D.plot.contourf(x='lat',y='long',col='alt', col_wrap=4,\n",
    "                         robust=True, vmin=-90, vmax=32, levels=20)\n",
    "plt.suptitle('Temperature at different altitudes', fontsize = 'xx-large',\n",
    "             weight = 'extra bold')\n",
    "plt.subplots_adjust(top=.92, right=.8, left=.05, bottom=.05)\n",
    "\n",
    "xr_tempC_Km=  xr.DataArray(mean_tempC_Km, dims=['alt'], coords={'alt': alt})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate pressure based on baseline temp field and assumed L; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#barometric formula\n",
    "def add_barometric_effects(T = 288.15-273.15, L = 0.0065, H = 0,  P0 = 101_325.00, g0 = 9.80665, M = 0.0289644, R = 8.3144598):\n",
    "    #barometric formula\n",
    "    #P = P0 * (1 - L * H / T0) ^ (g0 * M / (R * L))\n",
    "    #P = pressure\n",
    "    #P0 = pressure at sea level = 101_325.00 Pa\n",
    "    #L = temperature lapse rate = temperature lapse rate (K/m) in\n",
    "    #H = altitude (m)\n",
    "    #T0 = temperature at sea level = reference temperature (K)\n",
    "    #g0 = gravitational acceleration = gravitational acceleration: 9.80665 m/s2\n",
    "    #M = molar mass of air = molar mass of Earth's air: 0.0289644 kg/mol\n",
    "    #R = gas constant = universal gas constant: 8.3144598 J/(molÂ·K)\n",
    "    #L = temperature lapse rate\n",
    "    #T = temperature\n",
    "    T = T +273.15\n",
    "    if isinstance(T, xr.core.dataarray.DataArray):\n",
    "        T0 = T.sel(alt=0)\n",
    "        \n",
    "    else:\n",
    "        T0 = T[0]\n",
    "        print('used t[0]')\n",
    "        print(type(T))\n",
    "    #return P0 * (1 - L * H / (T0+273.15)) ** (g0 * M / (R * L))\n",
    "    return P0 * (T / T0) ** (g0 * M / (R * L.mean()))\n",
    "\n",
    "\n",
    "pressure = add_barometric_effects(T = xr_temp_3D, \n",
    "                                 L = xr_tempC_Km, \n",
    "                                 H = xr_temp_3D.alt,  P0 = 101_325.00, g0 = 9.80665, M = 0.0289644, R = 8.3144598)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xr_temp_pres = xr.merge(\n",
    "    [xr_temp_3D.rename(\"Temperature\"), \n",
    "     pressure.rename(\"Pressure\")]\n",
    "     )\n",
    "\n",
    "xr_temp_pres.Pressure.plot.contourf(x='lat',y='long', col='alt', col_wrap=4,\n",
    "                         robust=True, levels=20)\n",
    "plt.suptitle('Pressure at different altitudes', fontsize = 'xx-large',\n",
    "             weight = 'extra bold')\n",
    "plt.subplots_adjust(top=.92, right=.8, left=.05, bottom=.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# # make trajectory and get corresponding temp and pres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Z = a function of time and  X = sin of time and y = cos of time\n",
    "time = pd.to_datetime( np.arange(0, 3*60*60, 1), unit='s')\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "release_alt = 12_000 #Troposphere goes to about 12Km, thermal is about linear there\n",
    "step_alt = 1\n",
    "turn_rate = 3 #turns per hour\n",
    "x = (np.sin((time.hour+time.minute/60 +time.second/3600)*(2*np.pi)*turn_rate) +1) * size/2.50 +30\n",
    "y = (np.cos((time.hour+time.minute/60 +time.second/3600)*(2*np.pi)*turn_rate) +1 ) * size/2\n",
    "#create samples from normal distribution and sort them\n",
    "samples = stats.weibull_max.rvs(1.5, loc=0, scale=1, size=len(time), random_state=None)\n",
    "samples.sort()\n",
    "steps = samples/(samples.max()-samples.min()) /1.3  #normalize and shrink\n",
    "steps = steps - steps.min() #shift to 0\n",
    " #smaller step per time\n",
    "z = release_alt * (1- steps)\n",
    "\n",
    "plt.plot(time, z)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Altitude')\n",
    "plt.title('Altitude vs Time')\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(0, 12000)\n",
    "plt.show()\n",
    "#plot 3d trajectory of z by x and y\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x, y, z)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.set_zlim(0, 12000)\n",
    "plt.title('3D Trajectory')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#select from xarray the temperature at the pressure of the trajectory\n",
    "xr_x = xr.DataArray(x, dims=['time'], coords={'time': time})\n",
    "xr_y = xr.DataArray(y, dims=['time'], coords={'time': time})\n",
    "xr_z = xr.DataArray(z, dims=['time'], coords={'time': time})\n",
    "\n",
    "xr_traj_env = xr_temp_pres.interp(lat=xr_x,long=xr_y,alt=xr_z)#, method='nearest')\n",
    "xr_traj_env = xr_traj_env.interpolate_na(dim='time', method='linear', fill_value=\"extrapolate\")\n",
    "xr_traj_env.attrs =dict(units='seconds since 1970-01-01 00:00:00')\n",
    " # delay start of trajectory\n",
    "xr_traj_env['time'] = xr_traj_env.time +pd.Timedelta(hours=.75)\n",
    "\n",
    "xr_traj_env\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Put in Ballon data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ballon_alt_samples = np.arange(start=0,stop=max_alt_Km*1000+1,step=500)\n",
    "ballon_time = ballon_alt_samples/5\n",
    "ballon_time = pd.to_datetime(  ballon_time, unit='s')\n",
    "ballon_lat = [40, 100]\n",
    "ballon_long = [40, 125]\n",
    "launch_count = 2\n",
    "ballon_delay = pd.Timedelta(hours=7)# 7*60*60 # 7 hrs later in seconds\n",
    "launch_idx = np.arange(0,launch_count)\n",
    "def ballon_release(xr_temp_pres, ballon_alt_samples, ballon_time, ballon_lat, ballon_long, ballon_delay, launch_idx):\n",
    "    #ballon launch delay is in hours, will convert number to pd.Timedelta\n",
    "    ballon_delay = pd.Timedelta(hours=ballon_delay)\n",
    "    coords={'launch':[launch_idx],'time':(('time'),ballon_time+ballon_delay)}\n",
    "    xr_ballon_env = xr_temp_pres.interp(lat=\n",
    "                                    xr.DataArray([[ballon_lat[launch_idx]]]*len(ballon_time), \n",
    "                                                 dims=['time','launch'],\n",
    "                                                 coords=coords),\n",
    "                                    long=\n",
    "                                    xr.DataArray([[ballon_long[launch_idx]]]*len(ballon_time),\n",
    "                                                 dims=['time','launch'],\n",
    "                                                 coords=coords),\n",
    "                                    alt=\n",
    "                                    xr.DataArray([ballon_alt_samples],\n",
    "                                                 dims=['launch','time'],\n",
    "                                                 coords=coords),\n",
    "                                    )\n",
    "    xr_ballon_env= xr_ballon_env.interpolate_na(dim='time',method='linear', fill_value = 'extrapolate')\n",
    "    xr_ballon_env.attrs =dict(units='seconds since 1970-01-01 00:00:00')\n",
    "    return xr_ballon_env\n",
    "\n",
    "\n",
    "xr_ballon_env_0 = ballon_release(xr_temp_pres, ballon_alt_samples, ballon_time, ballon_lat, ballon_long, ballon_delay=0, launch_idx=0)\n",
    "xr_ballon_env_1 = ballon_release(xr_temp_pres, ballon_alt_samples, ballon_time, ballon_lat, ballon_long, ballon_delay=7, launch_idx=1)\n",
    "\n",
    "#TODO: remove the 'launch' dimension from the ballon_release function, then do not squeeze it out\n",
    "xr_ballon_env = xr.concat([xr_ballon_env_0.squeeze(), \n",
    "                           xr_ballon_env_1.squeeze()], \n",
    "                           dim='time')\n",
    "xr_ballon_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xr_traj_env = xr.concat([xr_traj_env, \n",
    "                         xr_ballon_env.drop('launch')],\n",
    "                           dim='time').sortby('time')\n",
    "xr_traj_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xr_traj_env.Temperature.plot()\n",
    "plt.suptitle('Temperature over time', fontsize = 'xx-large')\n",
    "plt.show()\n",
    "xr_traj_env.Pressure.plot()\n",
    "plt.suptitle('pressure over time', fontsize = 'xx-large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# downsample from xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#must be a datetime index in xarray\n",
    "# move xarray coordinate to variable\n",
    "xr_traj_env_time = xr_traj_env.reset_coords(['lat','long','alt'], drop=False)\n",
    "xr_traj_env_time = xr_traj_env_time.resample(time='5min', restore_coord_dims=True).mean().dropna(dim='time')\n",
    "xr_traj_env_time_coords = xr_traj_env_time\n",
    "#Move variable to xarray coordinate\n",
    "xr_traj_env_time = xr_traj_env_time.drop(['lat','long','alt'])\n",
    "xr_traj_env_time = xr_traj_env_time.expand_dims({\"lat\":xr_traj_env_time_coords.lat.values, \n",
    "                              'long':xr_traj_env_time_coords.long.values, \n",
    "                              'alt':xr_traj_env_time_coords.alt.values}) \n",
    "\n",
    "\n",
    "\n",
    "# toDO CHANGE THIS VARIABLE BELOW HERE\n",
    "#xarray make a multiindex of lat long alt and time\n",
    "\n",
    "#grp_traj_env = \n",
    "# may be useful : xr_traj_env_time.stack(alt_lat_long_time=['alt','lat','long','time'],create_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# # Using average values per time period along release; TODO: find more principled way to remove autocorrelation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# # Model temp and pressure varying by altitude, lat, & long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords={'alt_lat_long_time':\n",
    "                      np.arange(xr_traj_env_time.sizes['time'], dtype=int)\n",
    "                      }\n",
    "with pm.Model(coords=coords) as thermal_pres:\n",
    "    #Temp is in celcius\n",
    "    \n",
    "    Alt_ = pm.ConstantData('Altitude_m', xr_traj_env_time_coords.alt.values,#[bin_item.mid for bin_item in grp_traj_env.alt_bins.values], \n",
    "                                          dims='alt_lat_long_time' )\n",
    "    Lat_ = pm.ConstantData('Latitude', xr_traj_env_time_coords.lat.values,# [bin_item.mid for bin_item in grp_traj_env.lat_bins.values],\n",
    "                                        dims='alt_lat_long_time' )\n",
    "    Long_ = pm.ConstantData('Longitude', xr_traj_env_time_coords.long.values,#[bin_item.mid for bin_item in grp_traj_env.long_bins.values],\n",
    "                                          dims='alt_lat_long_time' )\n",
    "    Temp_ = pm.ConstantData('Temperature_Samples', xr_traj_env_time_coords.Temperature.values, dims='alt_lat_long_time' )\n",
    "    Pres_ = pm.ConstantData('Pressure_Samples', xr_traj_env_time_coords.Pressure.values, dims='alt_lat_long_time' )\n",
    "    #prior on effect on temp (degC) of altitude and lat, long\n",
    "    baseline_temp = pm.Normal('baseline_temp', mu=0, sigma=5) #'L'\n",
    "    Alt_effect_temp = pm.Normal('Alt_effect_temp_Km', mu=-6, sigma=.5)\n",
    "    Lat_effect_temp = pm.Normal('Lat_effect_temp', mu=0, sigma=.01)\n",
    "    Long_effect_temp = pm.Normal('Long_effect_temp', mu=0, sigma=.01)\n",
    "    #prior on temp and pressure\n",
    "    #TODO: PULL FROM DATABASE into a pm.Interpolated...maybe not: need relationship between data spreads?\n",
    "    mu_t = pm.Deterministic('mu_t',\n",
    "                               baseline_temp + Alt_effect_temp/1000 * Alt_ + Lat_effect_temp * Lat_ + Long_effect_temp * Long_, \n",
    "                               dims='alt_lat_long_time')\n",
    "    #mu_t = hierarchical_normal('temperature_mean', mu= mu_mu_t, sigma = 2, dims='alt_lat_long_time')\n",
    "    #mu_p = hierarchical_normal('pressure_mean', \n",
    "    P0 = Pres_[0]#101_325.00\n",
    "    g0 = 9.80665\n",
    "    M = 0.0289644\n",
    "    R = 8.3144598\n",
    "\n",
    "    mu_p= pm.Deterministic('mu_p',P0 *  ((mu_t+273.15)/(Temp_[0]+273.15)) ** (g0 * M / (R * (-Alt_effect_temp/1000))), #needed negative b/c the lapse is positive, but use addition in effect\n",
    "                                 dims='alt_lat_long_time')\n",
    "    '''add_barometric_effects(T = mu_t,#Temp_, \n",
    "                                 L = Alt_effect_temp/1000, H = Alt_,  \n",
    "                                 P0 = 101_325.00, g0 = 9.80665, M = 0.0289644, R = 8.3144598)'''\n",
    "    #add_barometric_effects = P0 * (T/T0) ** (g0 * M / (R * L))\n",
    "    #prior on error variation\n",
    "    sigma_t=pm.Exponential('model_error_t', 1/15)\n",
    "    sigma_p=pm.Exponential('model_error_p', 1/5000)\n",
    "    #adjusted temp - normal dist error term\n",
    "    obs_t = pm.Normal('obs_t', mu=mu_t, sigma=sigma_t, \n",
    "                    observed = Temp_, dims='alt_lat_long_time')\n",
    "    obs_p = pm.Normal('obs_p', mu=mu_p, sigma=sigma_p, \n",
    "                    observed = Pres_, dims='alt_lat_long_time')\n",
    "    \n",
    "pm.model_to_graphviz(thermal_pres)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the priors selected and their match to the observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with thermal_pres:\n",
    "    idata2 = pm.sample_prior_predictive(1000)\n",
    "az.plot_ppc(idata2, group='prior', kind='cumulative')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MCMC bayesian sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with thermal_pres:\n",
    "    idata2.extend(pm.sample(1000, tune=1000, chains = 4, cores=1))\n",
    "\n",
    "    az.plot_trace(idata2)\n",
    "    plt.subplots_adjust (hspace=0.4)#, wspace=0.4) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sortby_alt = xr.DataArray(idata2.constant_data.sortby('Altitude_m', ascending=False).alt_lat_long_time.values,\n",
    "                                dims=['alt_lat_long_time'])\n",
    "idata2.posterior = idata2.posterior.sortby( idx_sortby_alt) #posterior only for now\n",
    "idata2.constant_data = idata2.constant_data.sortby('Altitude_m', ascending=False)\n",
    "idata2.constant_data.alt_lat_long_time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xarray filter by values - used in grouping graphs\n",
    "lat_min = idata2.constant_data.Latitude.min()\n",
    "lat_max = idata2.constant_data.Latitude.max()\n",
    "long_min = idata2.constant_data.Longitude.min()\n",
    "long_max = idata2.constant_data.Longitude.max()\n",
    "lat_mid = (lat_min + lat_max)/2\n",
    "long_mid = (long_min + long_max)/2\n",
    "\n",
    "idx_north = idata2.constant_data.where(idata2.constant_data.Latitude>lat_mid, drop=True).alt_lat_long_time.values\n",
    "idx_south = idata2.constant_data.where(idata2.constant_data.Latitude<lat_mid, drop=True).alt_lat_long_time.values\n",
    "idx_east = idata2.constant_data.where(idata2.constant_data.Longitude>long_mid, drop=True).alt_lat_long_time.values\n",
    "idx_west = idata2.constant_data.where(idata2.constant_data.Longitude<long_mid, drop=True).alt_lat_long_time.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating class for labeling the altitude instead of variable index\n",
    "class DimCoordLabeller_alt(azl.BaseLabeller):\n",
    "    \"\"\"WIP.\"\"\"\n",
    "    def __init__(self, coords_ds):\n",
    "        self.coords_ds = xr.Dataset(coords)\n",
    "\n",
    "    def dim_coord_to_str(self, dim, coord_val, coord_idx):\n",
    "        \"\"\"WIP.\"\"\"#format decimals in f statement\n",
    "        temp =  self.coords_ds.sel(pointwise_sel=coord_val).items()\n",
    "        temp = [(v.values) for _,v in temp][0]\n",
    "        return f\"{temp:.2f}\" \n",
    "    \n",
    "coords = {\n",
    "    'alt_lat_long_time': xr.DataArray(\n",
    "        idata2.constant_data.Altitude_m.values, \n",
    "        dims=['pointwise_sel'],coords={'pointwise_sel': idata2.constant_data.alt_lat_long_time.values}\n",
    "    )\n",
    "}        \n",
    "labeller = DimCoordLabeller_alt(coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figures with lat in coulmns and long in rows\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "for i, ((N_S_label,N_S_idx), (E_W_label,E_W_idx)) in enumerate([[i,j] \n",
    "                                  for i in [('North',idx_north),('South',idx_south)] \n",
    "                                  for j in [('West',idx_west), ('East',idx_east)]]):\n",
    "    print(N_S_label,E_W_label)\n",
    "    ax[i].set_title(f'Lat: {N_S_label} Long: {E_W_label}')\n",
    "    idx = np.intersect1d(N_S_idx,E_W_idx)\n",
    "    az.plot_forest(idata2.sel(alt_lat_long_time=idx), \n",
    "                   var_names=['mu_t'],\n",
    "                   kind='ridgeplot', \n",
    "                   combined=True, ax= ax[i],\n",
    "                   labeller=labeller\n",
    "                   )\n",
    "    #align the y axis\n",
    "    #ax[i].set_ylim(0, 10000)\n",
    "    ax[i].set_xlim(-70, 10)\n",
    "    ax[i].grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "az.plot_forest(idata2, var_names=['mu_t'],kind='ridgeplot', combined=True,labeller=labeller)#,combine_dims='time_bins')\n",
    "az.plot_forest(idata2, var_names=['mu_p'],kind='ridgeplot', combined=True,labeller=labeller)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with thermal_pres:\n",
    "    # pymc sample posterior predictive check\n",
    "    pm.sample_posterior_predictive(idata2, extend_inferencedata=True)\n",
    "    az.plot_ppc(idata2, group='posterior', kind='cumulative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "az.plot_dist_comparison(idata2, kind='observed', labeller=labeller)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
