{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Try out Bayesian update to environmental estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "#%%\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import arviz as az\n",
    "import arviz.labels as azl\n",
    "import panel as pn\n",
    "pn.extension(comms=\"vscode\")\n",
    "\n",
    "\n",
    "#from hierarchical_normal_belk import hierarchical_normal\n",
    "#import itertools\n",
    "#!! conda install -c conda-forge flox\n",
    "#import flox\n",
    "#from flox.xarray import xarray_reduce # useful in doing multiple coord groupings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geoviews as gv\n",
    "gv.extension('bokeh')#, 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf_xarray.units # must be imported before pint_xarray\n",
    "import pint_xarray\n",
    "xp = pint_xarray\n",
    "ureg = xp.unit_registry\n",
    "from pint import Unit\n",
    "import pint\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -v -p pymc,numpy,matplotlib,hvplot,pandas,scipy,seaborn,xarray,arviz,panel,cartopy,geoviews,pint, plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.Generator(np.random.PCG64(1234))\n",
    "import geoviews.feature as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Arviz to use bokeh in a notebook\n",
    "az.style.use(\"arviz-doc\")\n",
    "# Confgure Bokeh as backend\n",
    "az.rcParams[\"plot.backend\"] = \"bokeh\"\n",
    "\n",
    "az.output_notebook()\n",
    "#get bokeh to work in vs code\n",
    "from bokeh.io import show\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "#from bokeh.plotting import show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def narange_unitless(*args, **kwargs):\n",
    "    # replace argument that come to the function\n",
    "    # as pint quantities with their magnitude\n",
    "    args = list(args)\n",
    "    args = [arg.magnitude if isinstance(arg, pint.Quantity) else arg for arg in args]\n",
    "    return np.arange(*args, **kwargs)'''\n",
    "\n",
    "def np_unitless(func):\n",
    "    # decorator to replace arguments that come to the function\n",
    "    # as pint quantities with their magnitude\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if args:\n",
    "            args = list(args)\n",
    "            args = [arg.magnitude if isinstance(arg, pint.Quantity) else arg for arg in args]\n",
    "        #print(args)\n",
    "        if kwargs:\n",
    "            kwargs = dict(kwargs)\n",
    "            kwargs = {k: v.magnitude if isinstance(v, pint.Quantity) else v for k, v in kwargs.items()}\n",
    "        #print(kwargs)\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@np_unitless\n",
    "def rng_normal(*args, **kwargs):\n",
    "    return rng.normal(*args, **kwargs)\n",
    "@np_unitless\n",
    "def np_arange(*args, **kwargs):\n",
    "    return np.arange(*args, **kwargs)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 150 #size of grid\n",
    "horz_offest = -150 #offset of grid from 0,0\n",
    "mean_tempC_Km = 6.5 *Unit('degC/km')#mean lapse rate\n",
    "max_alt_Km = 13  * Unit('km')#max altitude in km\n",
    "base = 0 * Unit('km')\n",
    "#keep lat and lonsquare for ease of matrixing\n",
    "lat = np_arange(horz_offest, size)\n",
    "lon= np_arange(0, size - horz_offest)\n",
    "alt = np_arange(0, max_alt_Km) * Unit('km') #?? can't use in numpy??\n",
    "alt= alt.to('m')#in meters\n",
    "if (horz_offest > size):\n",
    "    print (\"horz_offest cannot be greater than size\")\n",
    "    exit(-1)\n",
    "\n",
    "if (size < 1):\n",
    "    print (\"size cannot be less than 1\")\n",
    "    exit(-1)\n",
    "\n",
    "if (max_alt_Km < 0):\n",
    "    print (\"max_alt_Km cannot be negative\")\n",
    "    exit(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR is auto-regressive, MA is moving average; will only use AR \n",
    "def sample_AR_signal(n_samples, corr, mu=0, sigma=1):\n",
    "    assert 0 < corr < 1, \"Auto-correlation must be between 0 and 1\"\n",
    "    burn_samples = 100\n",
    "    n_samples=n_samples+burn_samples\n",
    "\n",
    "    # Find out the offset `c` and the std of the white noise `sigma_e`\n",
    "    # that produce a signal with the desired mean and variance.\n",
    "    # See https://en.wikipedia.org/wiki/Autoregressive_model\n",
    "    # under section \"Example: An AR(1) process\".\n",
    "    c = mu * (1 - corr)\n",
    "    sigma_e = np.sqrt((sigma ** 2) * (1 - corr ** 2))\n",
    "\n",
    "    # Sample the auto-regressive process.\n",
    "    signal = [c + np.random.normal(0, sigma_e)]\n",
    "    for _ in range(1, n_samples):\n",
    "        signal.append(c + corr * signal[-1] + np.random.normal(0, sigma_e))\n",
    "    \n",
    "    return np.array(signal[burn_samples:])\n",
    "    \n",
    "def compute_corr_lag_1(signal):\n",
    "    return np.corrcoef(signal[:-1], signal[1:])[0][1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Baseline thermal alonlatitude\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = .5\n",
    "samp_lat_base = sample_AR_signal(size-horz_offest, 0.5, mu=2, sigma=base_sigma)\n",
    "samp_lat= pd.DataFrame(samp_lat_base)\n",
    "print(compute_corr_lag_1(samp_lat_base))\n",
    "samp_lat.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Extend alonlonitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use latitudes as mean for AR signal alonlonitudes\n",
    "samp = sample_AR_signal(size-horz_offest, 0.75, mu=samp_lat, sigma=base_sigma)\n",
    "samp = pd.DataFrame(samp[:, :, 0])\n",
    "print(compute_corr_lag_1(samp.iloc[:,0]),compute_corr_lag_1(samp.iloc[0,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_temperature_env(samp):\n",
    "    x2, y2 = np.meshgrid(samp.index.values, samp.columns.values)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    axes = plt.axes(projection='3d')\n",
    "    axes.plot_surface(x2, y2,samp.values,cmap=cm.coolwarm,\n",
    "                          linewidth=0, antialiased=False)\n",
    "    axes.set_ylabel('lonitude')\n",
    "    axes.set_xlabel('Latitude')\n",
    "    axes.set_zlabel('Temperature')\n",
    "    # keeps padding between figure elements\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_temperature_env(samp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Add trend on top of the AR variation -- to baseline thermal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MA\n",
    "lat_inc_slope = -10/(size - horz_offest)  #deterministic slope of increase in temperature with latitude\n",
    "lat_inc_max = lat_inc_slope *(size-horz_offest) \n",
    "lon_inc_mu, lon_inc_std = 20/(size - horz_offest), .1  #mean and std of increase in temperature with lonitude\n",
    "\n",
    "def add_inc_MA(size, horz_offest, sample_AR_signal, samp_lat, lat_inc_max, lon_inc_mu, lon_inc_std):\n",
    "    lat_inc = np.linspace(0,lat_inc_max, len(samp_lat))\n",
    "    sample_lat_inc = samp_lat[0] + lat_inc\n",
    "    sample_lat_inc = pd.DataFrame(sample_lat_inc)\n",
    "#sample_lat_inc.plot()\n",
    "\n",
    "    samp_inc = sample_AR_signal(size-horz_offest, corr=0.5, mu=sample_lat_inc)\n",
    "    lon_inc = stats.norm.rvs(loc=lon_inc_mu, scale=lon_inc_std, size=(size-horz_offest,size-horz_offest), random_state=None)\n",
    "    lon_inc = np.cumsum(lon_inc, axis=0)\n",
    "    samp_inc = pd.DataFrame(samp_inc[:, :, 0]+lon_inc)\n",
    "    return samp_inc\n",
    "\n",
    "samp_inc = add_inc_MA(size, horz_offest, sample_AR_signal, samp_lat, lat_inc_max, lon_inc_mu, lon_inc_std)\n",
    "#bump temperature up to standard atmosphere\n",
    "samp_inc=samp_inc+15-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_temperature_env(samp_inc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative temperature source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\"air_temperature\")\n",
    "quantified_surf_temp = ds.pint.quantify()\n",
    "quantified_surf_temp=quantified_surf_temp.sortby(['lat','lon','time']).sel(lat=slice(15,75), lon=slice(200, 260))\n",
    "quantified_surf_temp.pint.dequantify(format=\"~P\").hvplot.image(x=\"lon\", y=\"lat\", z=\"air\", cmap=\"viridis\", groupby=\"time\", dynamic=True, width=600, height=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airi = surf_temp_i# quantified_surf_temp.interactive()\n",
    "w_latitude = pn.widgets.DiscreteSlider(name='Latitude', options=list(quantified_surf_temp.lat.values))\n",
    "w_rolling_window = pn.widgets.RadioButtonGroup(name='Rolling window', options=['1D', '7D', '30D'])\n",
    "baseline = airi.sel(lat=w_latitude).mean()\n",
    "pipeline = (\n",
    "    airi\n",
    "    .sel(lat=w_latitude)\n",
    "    .to_dataframe()\n",
    "    .drop(columns='lat')\n",
    "    .groupby('time').mean()\n",
    "    .rolling(w_rolling_window).mean()\n",
    "    - baseline\n",
    ")\n",
    "pipeline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = [ccrs.RotatedPole, ccrs.LambertCylindrical, ccrs.Geostationary, \n",
    "               ccrs.AzimuthalEquidistant, ccrs.OSGB, ccrs.EuroPP, ccrs.Gnomonic,\n",
    "               ccrs.Mollweide, ccrs.OSNI, ccrs.Miller, ccrs.InterruptedGoodeHomolosine,\n",
    "               ccrs.SouthPolarStereo,  ccrs.Orthographic, ccrs.NorthPolarStereo, ccrs.Robinson,\n",
    "               ccrs.LambertConformal, ccrs.AlbersEqualArea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = quantified_surf_temp.isel({'time':0}).squeeze().pint.dequantify(format=\"~P\").hvplot(geo=True, projection=ccrs.InterruptedGoodeHomolosine() )\n",
    "q.opts(width=600, height=400)\n",
    "# add country borders\n",
    "boarders_plot = gv.feature.borders().opts(line_color='black', line_width=2.5)\n",
    "features = gv.Overlay([gf.ocean, gf.land, gf.rivers, gf.lakes, gf.borders, gf.coastline])\n",
    "features * q * boarders_plot \n",
    "#display(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create globe projection in hvplot\n",
    "q =quantified_surf_temp.pint.dequantify(format=\"~P\").hvplot.quadmesh(\n",
    "    'lon', 'lat', 'air', projection='LambertConformal',\n",
    ")\n",
    "show(hv.render(q))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Extend into atmosphere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#allow for inversion by having random lapse rate at diff altitudes\n",
    "def add_altitude_effects(rng, samp_inc, mean_tempC_Km, max_alt_Km):\n",
    "    alt_dim = xr.DataArray(data=np_arange(max_alt_Km), dims=\"alt\",attrs={\"units\":\"km\"}, name='alt') \n",
    "    alt_dim=alt_dim.pint.quantify() #convert to pint units for multiplication later\n",
    "    tempC_Km = xr.DataArray(data=rng_normal(loc=mean_tempC_Km, scale=mean_tempC_Km/100, size=max_alt_Km),coords={'alt': alt_dim}, name='LapseRate')\n",
    "    tempC_Km.attrs[\"units\"] = \"degC/km\"\n",
    "    tempC_Km.alt.attrs[\"units\"] = \"km\" # the dim pint unit not preserved\n",
    "    tempC_Km=tempC_Km.pint.quantify()\n",
    "    #tempC_Km['alt'] = tempC_Km.alt.pint.quantify() # dims can't currently realy hold pint.units\n",
    "        \n",
    "    #if samp_inc is not an xarray make it one\n",
    "    if not isinstance(samp_inc, xr.DataArray):\n",
    "        xr_samp_inc = xr.DataArray(data=samp_inc.values, dims=[\"lat\",\"lon\"],coords={\"lat\":('lat',samp_inc.index.values,{\"units\":\"degrees_north\"}),\"lon\":('lon',samp_inc.columns.values,{\"units\":\"degrees_east\"})})\n",
    "    else:\n",
    "        xr_samp_inc = samp_inc\n",
    "    try:\n",
    "        xr_samp_inc.attrs[\"units\"] = \"degC\"\n",
    "        xr_samp_inc = xr_samp_inc.pint.quantify()\n",
    "    except:\n",
    "        print(f'did not convert units to degC')\n",
    "\n",
    "        pass\n",
    "\n",
    "    temperature = xr_samp_inc - tempC_Km * alt_dim\n",
    "    temperature.name = \"Temperature\"\n",
    "    return temperature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_3D = add_altitude_effects(rng, samp_inc, mean_tempC_Km, max_alt_Km)\n",
    "\n",
    "\n",
    "# Check for NaN values\n",
    "if np.any(np.isnan(temp_3D)):\n",
    "    raise ValueError(\"Temperature values cannot be NaN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_temp_3D_new = add_altitude_effects(rng, quantified_surf_temp.air, mean_tempC_Km, max_alt_Km)\n",
    "xr_temp_3D = xr_temp_3D_new\n",
    "xr_temp_3D['alt']=xr_temp_3D.alt.pint.to(\"m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_temp_3D.pint.to('degC').pint.dequantify().hvplot.line(x=\"alt\", ylim=[-60,30])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "xr_temp_3D = xr.DataArray(temp_3D, dims=['lat', 'lon', 'alt'], coords={'lat': lat, 'lon': lon, 'alt': alt})\n",
    "fig = xr_temp_3D.plot.contourf(x='lat',y='lon',col='alt', col_wrap=4,\n",
    "                         robust=True)#, vmin=-90, vmax=32, levels=20)\n",
    "plt.suptitle('Temperature at different altitudes', fontsize = 'xx-large',\n",
    "             weight = 'extra bold')\n",
    "plt.subplots_adjust(top=.92, right=.8, left=.05, bottom=.05)\n",
    "plt.show()\n",
    " # plot temperature at different altitudes for lat 55 and lon90 and lat 80 and lon90 and lat 100 and lon100 \n",
    "\n",
    "xr_temp_3D.sel(lat=55, lon=90).plot(y='alt')\n",
    "xr_temp_3D.sel(lat=80, lon=90).plot(y='alt')\n",
    "xr_temp_3D.sel(lat=100, lon=10).plot(y='alt')\n",
    "title = 'Temperature at different altitudes '\n",
    "plt.title(title, fontsize = 'xx-large', weight = 'extra bold')\n",
    "plt.legend(['lat 55 and lon90', 'lat 80 and lon90', 'lat 100 and lon10'])\n",
    "\n",
    "\n",
    "\n",
    "xr_tempC_Km=  xr.DataArray(mean_tempC_Km, dims=['alt'], coords={'alt': alt})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xr_temp_3D.name = 'temp'\n",
    "xr_temp_3D.attrs['name'] = 'temp'\n",
    "xr_temp_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copilot: project this onto globe using xarray\n",
    "# https://xarray.pydata.org/en/stable/plotting.html\n",
    "#.sel(alt=10000)\n",
    "p = xr_temp_3D.pint.dequantify(format='~P').hvplot.quadmesh(\n",
    "    'lon', 'lat', 'Temperature', projection=ccrs.Orthographic(-90, 30))\n",
    "#p.axes.set_global()\n",
    "#p.axes.coastlines()\n",
    "p.opts(global_extent=True, frame_height=540, cmap='viridis', clim=(150,330))\n",
    "\n",
    "p.relabel(\"Temperature at 10km\")\n",
    "\n",
    "'''    ax.set_extent([-180, 180, -90, 90])\n",
    "    ax.set_aspect(\"auto\")\n",
    "    ax.set_title(ax.get_title().replace(\"altitude = \",\"\"))\n",
    "    ax.set_xlabel(\"lonitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    ax.set_xticks([-180, -90, 0, 90, 180], crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks([-90, -45, 0, 45, 90], crs=ccrs.PlateCarree())\n",
    "    ax.tick_params(labelsize=8)'''\n",
    "p * boarders_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check slopes\n",
    "\n",
    "xr_4_slope = xr_temp_3D.sel(alt=10000*ureg('m'),lon=250)\n",
    "slope_lat = xr_4_slope.diff('lat')/xr_4_slope.lat.diff('lat')\n",
    "slope_lat.mean()\n",
    "print(slope_lat.mean(),'\\n---------------\\n',lat_inc_slope, '\\n\\n')\n",
    "xr_4_slope = xr_temp_3D.sel(alt=10000,lat=25)\n",
    "slope_lon= xr_4_slope.diff('lon')/xr_4_slope.lon.diff('lon')\n",
    "slope_lon.mean()\n",
    "print(slope_lon.mean(),'\\n---------------\\n',lon_inc_mu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate pressure based on baseline temp field and assumed L; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#barometric formula\n",
    "def add_barometric_effects(T = 288.15 , L = 0.0065, H = 0.0,  P0 = 101_325.00, g0 = 9.80665, M = 0.0289644 , R =  8.3144598):\n",
    "    #barometric formula\n",
    "    #P = P0 * (1 - L * H / T0) ^ (g0 * M / (R * L))\n",
    "    #P = pressure\n",
    "    #P0 = pressure at sea level = 101_325.00 Pa\n",
    "    try:\n",
    "        P0 = P0   * Unit(\"Pa\")\n",
    "    except(AttributeError):\n",
    "        pass\n",
    "    #H = altitude (m)\n",
    "    try:\n",
    "        H = H   * Unit(\"m\")\n",
    "    except(AttributeError):\n",
    "        pass\n",
    "    #T0 = temperature at sea level = reference temperature (K)\n",
    "    try:\n",
    "        T = T  * Unit('degK')\n",
    "    except(AttributeError):\n",
    "        pass\n",
    "    #g0 = gravitational acceleration = gravitational acceleration: 9.80665 m/s2\n",
    "    g0 = g0   * Unit(\"m/s2\")\n",
    "    #M = molar mass of air = molar mass of Earth's air: 0.0289644 kg/mol\n",
    "    M = M  * Unit(\"kg/mol\")\n",
    "    #R = gas constant = universal gas constant: 8.3144598 J/(mol·K)\n",
    "    R = R  * Unit(\"J/(mol·K)\")\n",
    "    #L = temperature lapse rate: change in degrees per meter\n",
    "    try:\n",
    "        L = L  * Unit(\"degC/km\") \n",
    "    except(AttributeError):\n",
    "        pass\n",
    "    #T = temperature\n",
    "    if isinstance(T, xr.core.dataarray.DataArray):\n",
    "        T0 = T.sel(alt=0)\n",
    "        \n",
    "    else:\n",
    "        T0 = T[0]\n",
    "        print('used t[0]')\n",
    "        print(type(T))\n",
    "    # use pint to convert to kelvin\n",
    "    T0 = T0.pint.to(\"K\")\n",
    "\n",
    "    #return P0 * (1 - L * H / (T0+273.15)) ** (g0 * M / (R * L))\n",
    "    #return P0 * (1 + L * H / (T0+273.15)) ** (-g0 * M / (R * L))\n",
    "    return P0 * (1 + (-L)*H/ T0) ** (-g0 * M / (R * (-L)))\n",
    "\n",
    "\n",
    "'''pressure = add_barometric_effects(T = xr_temp_3D, \n",
    "                                 L = mean_tempC_Km, \n",
    "                                 H = xr_temp_3D.alt,  P0 = 101_325.00, g0 = 9.80665, M = 0.0289644, R = 8.3144598)'''\n",
    "#put in ground temperature effects on pressure\n",
    "P0_space = add_barometric_effects(T= xr_temp_3D, H=1 , P0 = 101_325.00, )\n",
    "\n",
    "pressure = add_barometric_effects(T = xr_temp_3D, \n",
    "                                 L = mean_tempC_Km, \n",
    "                                 H = xr_temp_3D.alt,  P0 = P0_space, g0 = 9.80665, M = 0.0289644, R = 8.3144598)\n",
    "pressure_backup = pressure.copy()\n",
    "pressure.name = \"Pressure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boarders_plot * pressure.pint.dequantify().hvplot('lat','lon') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add measurement noise to pressure\n",
    "pressure=rng_normal(loc=pressure_backup, scale=10000)-xr.zeros_like( pressure)#pressure_backup.pipe(lambda x: rng_normal(loc=x, scale=10000))-xr.zeros_like( pressure)\n",
    "pressure.attrs[\"units\"] = \"Pa\"\n",
    "pressure.pint.quantify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xr_temp_pres = xr.merge(\n",
    "    [xr_temp_3D.rename(\"Temperature\"), \n",
    "     pressure.rename(\"Pressure\")], combine_attrs=\"override\"\n",
    "     )\n",
    "xr_temp_pres=xr_temp_pres.pint.quantify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_temp_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_temp_pres_t0=xr_temp_pres.isel({'time':[0]}).squeeze()\n",
    "xr_temp_pres_t0.Pressure.plot.contourf(x='lat',y='lon', col='alt', col_wrap=4,\n",
    "                         robust=True, levels=20)\n",
    "plt.suptitle('Pressure at different altitudes', fontsize = 'xx-large',\n",
    "             weight = 'extra bold')\n",
    "plt.subplots_adjust(top=.92, right=.8, left=.05, bottom=.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#xr_temp_pres.mean(['lat', 'lon']).plot.scatter(x='alt', y='Pressure' )\n",
    "# add error bars to scatter plot\n",
    "plt.errorbar(x=xr_temp_pres_t0.alt, y=xr_temp_pres_t0.mean(['lat', 'lon']).Pressure,\n",
    "                yerr=2*xr_temp_pres_t0.std(['lat', 'lon']).Pressure, fmt='o', alpha=0.5)\n",
    "\n",
    "plt.title('Pressure at different altitudes', fontsize = 'xx-large',\n",
    "                weight = 'extra bold')\n",
    "plt.xlabel('Altitude (m)', fontsize = 'x-large',\n",
    "                weight = 'extra bold')\n",
    "plt.ylabel('Pressure (Pa)', fontsize = 'x-large',\n",
    "                weight = 'extra bold')\n",
    "plt.subplots_adjust(top=.92, right=.8, left=.05, bottom=.05)\n",
    "#plt.show()\n",
    "xr_temp_pres_dequant = xr_temp_pres_t0.pint.dequantify()\n",
    "# plot pressure at different altitudes for lat 55 and lon290 and lat 80 and lon90\n",
    "xr_temp_pres_dequant.sel(lat=55, lon=290, method='nearest').Pressure.plot.line(x='alt', label = 'lat 55, lon290')\n",
    "xr_temp_pres_dequant.sel(lat=80, lon=290, method='nearest').Pressure.plot.line(x='alt', label = 'lat 80, lon290')\n",
    "xr_temp_pres_dequant.sel(lat=100, lon=210, method='nearest').Pressure.plot.line(x='alt', label = 'lat 100, lon210')\n",
    "\n",
    "title = 'Pressure at different altitudes '\n",
    "plt.title(title, fontsize = 'xx-large', weight = 'extra bold')\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make trajectory and get corresponding temp and pres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Z = a function of time and  X = sin of time and y = cos of time\n",
    "recording_time_hr = 6\n",
    "time = pd.to_datetime( np_arange(0, recording_time_hr*60*60, 1), unit='s') # wait until after flight calaculation + pd.DateOffset(years=2013-1970, months=0, days=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(xr = None):\n",
    "    return xr.max() - xr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "release_alt = 12_000 * Unit('m') #Troposphere goes to about 12Km, thermal is about linear there\n",
    "step_alt = 1\n",
    "turn_rate = 1.14 * Unit('turn/hr') #turns per hour\n",
    "display(turn_rate)\n",
    "x = (np.sin((time.hour+time.minute/60 +time.second/3600)*(2*np.pi)*turn_rate) +1) * (spread(xr_temp_pres.lat.data) )/2.50 + xr_temp_pres.lat.min().data +5 \n",
    "y = (np.cos((time.hour+time.minute/60 +time.second/3600)*(2*np.pi)*turn_rate) +1 ) * (spread(xr_temp_pres.lon.data) )/3 +xr_temp_pres.lon.min().data +5 \n",
    "#create samples from normal distribution and sort them\n",
    "samples = stats.weibull_max.rvs(2.9, loc=0, scale=1, size=len(time), random_state=None)\n",
    "samples.sort()\n",
    "steps = samples/(samples.max()-samples.min()) /1.3  #normalize and shrink\n",
    "steps = steps - steps.min() #shift to 0\n",
    " #smaller step per time\n",
    "z = release_alt * (1- steps)\n",
    "plt.plot(time, z)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Altitude')\n",
    "plt.title('Altitude vs Time')\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(0, 12000)\n",
    "plt.show()\n",
    "\n",
    "#plot 3d trajectory of z by x and y\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x, y, z.data, label='Trajectory')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.set_zlim(0, 12000)\n",
    "plt.title('3D Trajectory')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time.year[0] == 1970:\n",
    "    time+= pd.DateOffset(years=2013-1970, months=0, days=6)\n",
    "#select from xarray the temperature at the pressure of the trajectory\n",
    "xr_traj_env = xr.DataArray()\n",
    "\n",
    "xr_x = xr.DataArray(x, dims=['time'], coords={'time': time}, attrs={\"units\":\"degrees_north\"})\n",
    "xr_y = xr.DataArray(y, dims=['time'], coords={'time': time}, attrs={\"units\":\"degrees_east\"})\n",
    "xr_z = xr.DataArray(z, dims=['time'], coords={'time': time}, attrs={\"units\":\"m\"})\n",
    "with xr.set_options(keep_attrs=True):\n",
    "    xr_traj_env = xr_temp_pres.interp(lat=xr_x,lon=xr_y,alt=xr_z, time=time, method='nearest')\n",
    "    xr_traj_env = xr_traj_env.interpolate_na(dim='time', method='linear', fill_value=\"extrapolate\")\n",
    "#xr_traj_env.attrs =dict(units='seconds since 1970-01-01 00:00:00')\n",
    " # delay start of trajectory\n",
    "xr_traj_env['time'] = xr_traj_env.time +pd.Timedelta(hours=.75)\n",
    "\n",
    "xr_traj_env.pint.quantify() #TODO: 'quantify like' previous, or just skip it?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Put in Ballon data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stop_alt = max_alt_Km.to('m')+1*ureg('m')\n",
    "ballon_alt_samples = np_arange(start=0,stop=stop_alt,step=500)\n",
    "ballon_time = ballon_alt_samples/5\n",
    "ballon_time = pd.to_datetime(  ballon_time, unit='s')\n",
    "ballon_lat = [xr_temp_pres.lat.min().data +10, xr_temp_pres.lat.max().data-10]\n",
    "ballon_lon= [xr_temp_pres.lon.min().data + 10 , xr_temp_pres.lon.max().data - 10]\n",
    "'''ballon_lat = [55, 120, 50, 139, 90]\n",
    "ballon_lon= [15, 10, 90, 95, 25]'''\n",
    "launch_count = len(ballon_lat)\n",
    "ballon_delay = [pd.DateOffset(years=2013-1970, months=0, days=6, hours=i  )\n",
    "                for i in [0,9] #[0,5,6.5,8,9]\n",
    "                ]# 7*60*60 # 7 hrs later in seconds\n",
    "launch_idx = np_arange(0,launch_count)\n",
    "def ballon_release(xr_temp_pres, ballon_alt_samples, ballon_time, ballon_lat, ballon_lon, ballon_delay, launch_idx):\n",
    "    #ballon launch delay is in hours, will convert number to pd.Timedelta\n",
    "    #ballon_delay = pd.Timedelta(hours=ballon_delay)\n",
    "    coords={'time':(('time'),ballon_time+ballon_delay)}\n",
    "    xr_ballon_env = xr_temp_pres.interp(lat=\n",
    "                                    xr.DataArray([ballon_lat[launch_idx]]*len(ballon_time), \n",
    "                                                 dims=['time'],\n",
    "                                                 coords=coords),\n",
    "                                    lon=\n",
    "                                    xr.DataArray([ballon_lon[launch_idx]]*len(ballon_time)\n",
    "                                    ,\n",
    "                                                 dims=['time'],\n",
    "                                                 coords=coords),\n",
    "                                    alt=\n",
    "                                    xr.DataArray(ballon_alt_samples,\n",
    "                                                 dims=['time'],\n",
    "                                                 coords=coords),\n",
    "                                    time=\n",
    "                                    xr.DataArray(ballon_time+ballon_delay,\n",
    "                                                  dims=['time'],\n",
    "                                                  coords=coords),\n",
    "                                    method='nearest'\n",
    "                                    )\n",
    "    xr_ballon_env= xr_ballon_env.interpolate_na(dim='time',method='linear', fill_value = 'extrapolate')\n",
    "    #xr_ballon_env.attrs =dict(units='seconds since 1970-01-01 00:00:00')\n",
    "    return xr_ballon_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xr_ballon_env_lst = [ballon_release(xr_temp_pres, ballon_alt_samples, ballon_time,\n",
    "\n",
    "                                 ballon_lat, ballon_lon, ballon_delay[i], launch_idx=i).squeeze()\n",
    "                                   for i in np_arange(launch_count)\n",
    "\n",
    "                    ]\n",
    "xr_ballon_env = xr.concat(xr_ballon_env_lst, dim='time')\n",
    "\n",
    "\n",
    "\n",
    "xr_ballon_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  print(f' needs ballon',  xr_traj_env.attrs['needs_ballon'] )\n",
    "except(KeyError):\n",
    "    xr_traj_env = xr.concat([xr_traj_env, \n",
    "                         xr_ballon_env],\n",
    "                           dim='time', \n",
    "                           join='outer',\n",
    "                           combine_attrs='override').sortby('time')\n",
    "    xr_traj_env.attrs['needs_ballon'] = False\n",
    "    print('added ballon data to trajectory')\n",
    "\n",
    "xr_traj_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot 3d trajectory of z by x and y\n",
    "\n",
    "def plot_traj_3d(xarray=None, elev = 90, azim = -90, roll = 0, **kwargs):\n",
    "    title_str = '3D Trajectory'\n",
    "    # get values from kwargs\n",
    "    if kwargs:\n",
    "        for key, value in kwargs['kwargs'].items():\n",
    "            if key == 'elev':\n",
    "                elev = value\n",
    "            elif key == 'azim':\n",
    "                azim = value\n",
    "            elif key == 'roll':\n",
    "                roll = value\n",
    "            elif key == 'title':\n",
    "                title_str = value\n",
    "            else:\n",
    "                print(f'Unknown keyword argument {kwargs}')\n",
    "\n",
    "    print(elev, azim, roll, title_str)\n",
    "    xr_x= xarray\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(xr_x.lat,\n",
    "            xr_x.lon,\n",
    "            xr_x.alt)\n",
    "    ax.set_xlabel('Lat')\n",
    "    ax.set_ylabel('lon')\n",
    "    ax.set_zlabel('Alt')\n",
    "    ax.set_zlim(0, xr_x.alt.max())\n",
    "    #change the view angle\n",
    "    ax.view_init(elev, azim, roll)\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "view_perspectives ={'top': dict(elev=90, azim=-90, roll=0, title='Top View'), \n",
    "                    'ortho': dict(elev=30, azim=-40, roll=0, title='Orthographic View'), \n",
    "                    'side': dict(elev=0, azim=90, roll=0, title='Side View'), \n",
    "                    'front': dict(elev=0, azim=0, roll=0, title='Front View')}\n",
    "print(view_perspectives['front'])\n",
    "\n",
    "'''fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(221, projection='3d')\n",
    "ax2 = fig.add_subplot(222, projection='3d')\n",
    "ax3 = fig.add_subplot(223, projection='3d')\n",
    "ax4 = fig.add_subplot(224, projection='3d')\n",
    "#plot each view'''\n",
    "ax1 = plot_traj_3d(xr_traj_env, kwargs=view_perspectives['top'])\n",
    "# set subplot axes title\n",
    "\n",
    "\n",
    "ax2 = plot_traj_3d(xr_traj_env, kwargs=view_perspectives['ortho'])\n",
    "#ax2.set_title('Orthographic View')\n",
    "ax3 = plot_traj_3d(xr_traj_env, kwargs=view_perspectives['side'])\n",
    "#ax3.set_title('Side View')\n",
    "ax4 = plot_traj_3d(xr_traj_env, kwargs=view_perspectives['front'])\n",
    "#ax4.set_title('Front View')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new 3d trajectory plot using plotly\n",
    "\n",
    "#import plotly.express as px\n",
    "\n",
    "def plot_traj_3d_plotly(xarray=None, elev = 90, azim = -90, roll = 0, **kwargs):\n",
    "    title_str = '3D Trajectory'\n",
    "    # get values from kwargs\n",
    "    if kwargs:\n",
    "        for key, value in kwargs['kwargs'].items():\n",
    "            if key == 'elev':\n",
    "                elev = value\n",
    "            elif key == 'azim':\n",
    "                azim = value\n",
    "            elif key == 'roll':\n",
    "                roll = value\n",
    "            elif key == 'title':\n",
    "                title_str = value\n",
    "            else:\n",
    "                print(f'Unknown keyword argument {kwargs}')\n",
    "\n",
    "    print(elev, azim, roll, title_str)\n",
    "    xr_x= xarray\n",
    "    fig = go.Figure(data=[go.Scatter3d(x=xr_x.lat,\n",
    "                                       y=xr_x.lon,\n",
    "                                       z=xr_x.alt,\n",
    "                                       mode='markers')])\n",
    "    fig.update_layout(scene=dict(xaxis_title='Lat',\n",
    "                                 yaxis_title='Lon',\n",
    "                                 zaxis_title='Alt'),\n",
    "                      title=title_str,\n",
    "                      width=700,\n",
    "                      height=700,\n",
    "                      margin=dict(r=20, b=10, l=10, t=10))\n",
    "    fig.show()\n",
    "\n",
    "plot_traj_3d_plotly(xr_traj_env, kwargs=view_perspectives['top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_pres_combo_hvplot = xr_traj_env.Temperature.hvplot.scatter(x='time',color='black',\n",
    "                                                                title=\"All Temp recorded\",\n",
    "                                                                width=500) + xr_traj_env.Pressure.hvplot.scatter(x='time', color='black',\n",
    "                                                                                                                 title =\"All Pressure recorded\",\n",
    "                                                                                                                 width=500)\n",
    "\n",
    "display(temp_pres_combo_hvplot )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# downsample from xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#must be a datetime index in xarray\n",
    "# move xarray coordinate to variable\n",
    "\n",
    "'''xr_traj_env_time = xr_traj_env.reset_coords(['lat','lon','alt'], drop=False)\n",
    "resample_period = '10min'\n",
    "xr_traj_env_time = xr_traj_env_time.resample(time=resample_period, restore_coord_dims=True).mean().dropna(dim='time')\n",
    "xr_traj_env_time_coords = xr_traj_env_time.copy(deep=True)\n",
    "#Move variable to xarray coordinate multiindex\n",
    "xr_traj_env_time= xr_traj_env.reset_coords(['lat','lon','alt'], drop=False\n",
    "                                           ).resample(time=resample_period, restore_coord_dims=True\n",
    "                                                      ).mean().dropna(dim='time'\n",
    "                                                                      ).set_coords(['lat','lon','alt']\n",
    "                                                                                   ).set_xindex(['alt','lat','lon'])\n",
    "xr_traj_env_time'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_traj_env_time = xr_traj_env.reset_coords(['lat','lon','alt'], drop=False)\n",
    "resample_period = '10min'\n",
    "xr_traj_env_time = xr_traj_env_time.resample(time=resample_period, restore_coord_dims=True).mean().dropna(dim='time')\n",
    "# get back all the ballon data - undo downsample\n",
    "xr_traj_env_time_coords =  xr.combine_nested([xr_traj_env_time.set_coords(['lat','lon','alt']), \n",
    "                   xr_ballon_env], \n",
    "                   join='outer',\n",
    "                   concat_dim='time'\n",
    "                   ).sortby('time'\n",
    "                            )\n",
    "xr_traj_env_time = xr_traj_env_time_coords.set_coords(['lat','lon','alt']\n",
    "                                         ).set_xindex(['alt','lat','lon'])\n",
    "xr_traj_env_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_traj_3d(xr_traj_env_time, kwargs=view_perspectives['ortho'])\n",
    "plt.show()\n",
    "\n",
    "xr_traj_env_time_coords.Temperature.hvplot.scatter(x='time',y='Temperature', color='black', \n",
    "                                                   title=\"Temperature recorded and binned\",\n",
    "                                                   width=500) + \\\n",
    "xr_traj_env_time_coords.Pressure.hvplot.scatter(x='time', y='Pressure', color='black', \n",
    "                                                title=\"Pressure recorded and binned\",\n",
    "                                                width=500)\n",
    "\n",
    "#make each dot black\n",
    "\n",
    "# toDO CHANGE THIS VARIABLE BELOW HERE\n",
    "#xarray make a multiindex of lat lonalt and time\n",
    "\n",
    "#grp_traj_env = \n",
    "# may be useful : xr_traj_env_time.stack(alt_lat_lon_time=['alt','lat','lon','time'],create_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traj_3d_plotly(xr_traj_env_time, kwargs=view_perspectives['top'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model temp and pressure varying by altitude, lat, & lon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data\n",
    "#TODO: replace this with xarray built in function\n",
    "\n",
    "def normalization(xarray=None):\n",
    "    xr_x = xarray\n",
    "    revert_min, revert_spread = xr_x.min(), xr_x.max()-xr_x.min()\n",
    "    xr_x = (xr_x - revert_min) / revert_spread\n",
    "    return xr_x, revert_min, revert_spread\n",
    "def revert_normalization(xarray=None, revert_min=None, revert_spread=None):\n",
    "    xr_x = xarray\n",
    "    xr_x = xr_x * revert_spread + revert_min\n",
    "    return xr_x\n",
    "def convert_normalization(xr_old=None, xr_new=None):\n",
    "    if xr_new.lat.values.size > 0:\n",
    "        xr_new['lat_norm'] = (xr_new.lat - xr_old.attrs['sdz_lat_min']) / xr_old.attrs['sdz_lat_spread'] \n",
    "    if xr_new.lon.values.size > 0:\n",
    "        xr_new['lon_norm'] = (xr_new.lon - xr_old.attrs['sdz_lon_min']) / xr_old.attrs['sdz_lon_spread']\n",
    "\n",
    "xr_traj_env_time['stz_lat'], sdz_min, stz_spread = normalization(xr_traj_env_time.lat)\n",
    "xr_traj_env_time.attrs['sdz_lat_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_lat_spread']  =stz_spread.values\n",
    "xr_traj_env_time['stz_lon'], sdz_min, stz_spread = normalization(xr_traj_env_time.lon)\n",
    "xr_traj_env_time.attrs['sdz_lon_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_lon_spread']  =stz_spread.values\n",
    "xr_traj_env_time['stz_alt'], sdz_min, stz_spread = normalization(xr_traj_env_time.alt)\n",
    "xr_traj_env_time.attrs['sdz_alt_min'] =sdz_min.values\n",
    "xr_traj_env_time.attrs['sdz_alt_spread']  =stz_spread.values\n",
    "\n",
    "xr_traj_env_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_traj_env_time.Temperature.attrs['units']= ureg.degK\n",
    "xr_traj_env_time.Pressure.attrs['units']= ureg.Pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_traj_env_time=xr_traj_env_time.pint.quantify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''coords={'alt_lat_lon_time':\n",
    "                      arange_2(xr_traj_env_time.sizes['time'], dtype=int)\n",
    "                      }'''\n",
    "with pm.Model() as thermal_pres:\n",
    "    #set coords in here to be mutable\n",
    "    thermal_pres.add_coord('alt_lat_lon_time', np_arange(xr_traj_env_time.sizes['time'], dtype=int), mutable=True)\n",
    "    #Temp is in celcius\n",
    "    \n",
    "    Alt_ = pm.MutableData('Altitude_m', xr_traj_env_time.alt.values,# use normal un-normalized data\n",
    "                                          dims='alt_lat_lon_time' )\n",
    "    Lat_ = pm.MutableData('Latitude', xr_traj_env_time.stz_lat.values,\n",
    "                                        dims='alt_lat_lon_time' )\n",
    "    lon_ = pm.MutableData('lonitude', xr_traj_env_time.stz_lon.values,\n",
    "                                          dims='alt_lat_lon_time' )\n",
    "    Temp_ = pm.MutableData('Temperature_Samples', xr_traj_env_time.Temperature.pint.to('C').values, dims='alt_lat_lon_time' )\n",
    "    Pres_ = pm.MutableData('Pressure_Samples', xr_traj_env_time.Pressure.values, dims='alt_lat_lon_time' )\n",
    "    #prior on effect on temp (degC) of altitude and lat, lon\n",
    "    baseline_temp = pm.Normal('baseline_temp', mu=17, sigma=7)\n",
    "    Alt_effect_temp = pm.Normal('Alt_effect_temp_Km', mu=-7, sigma=.5)\n",
    "    Lat_effect_temp = pm.Normal('Lat_effect_temp', mu=-0.05, sigma=.01)\n",
    "    lon_effect_temp = pm.Normal('lon_effect_temp', mu=0.05, sigma=.01)\n",
    "    Lat_lon_effect_temp = 0  #pm.Normal('Lat_lon_effect_temp', mu=0, sigma=1)\n",
    "    #prior on temp and pressure\n",
    "    #TODO: PULL FROM DATABASE into a pm.Interpolated...maybe not: need relationship between data spreads?\n",
    "    mu_t = pm.Deterministic('mu_t',\n",
    "                               baseline_temp + \n",
    "                               Alt_effect_temp/1000 * Alt_ + \n",
    "                               Lat_effect_temp * Lat_ + \n",
    "                               lon_effect_temp * lon_ + \n",
    "                               Lat_lon_effect_temp * Lat_ * lon_, \n",
    "                               dims='alt_lat_lon_time')\n",
    "\n",
    "    P0 = pm.Normal('P0', mu=1, sigma=.01)*101_325.00 # lat/loninfluence on ground level temp captured in Temp_0\n",
    "    g0 = 9.80665\n",
    "    M = 0.0289644\n",
    "    R = 8.3144598\n",
    "    # NOTE: Temp_[0] is not the lowest altitude temperature, but the first temperature in the array\n",
    "    Temp_0 = baseline_temp+ Lat_effect_temp * Lat_ + lon_effect_temp * lon_ # account for lat/loninfluence on ground level temp\n",
    "    mu_p= pm.Deterministic('mu_p',P0 *  ((mu_t+273.15)/(Temp_0+273.15)) ** (-g0 * M / (R * (Alt_effect_temp/1000))), \n",
    "                                 dims='alt_lat_lon_time')\n",
    "    #add_barometric_effects = P0 * (T/T0) ** (-g0 * M / (R * L))\n",
    "    #prior on error variation\n",
    "    sigma_t=pm.Exponential('model_error_t', 1/5)\n",
    "    sigma_p=pm.Exponential('model_error_p', 1/500)\n",
    "    #adjusted temp - normal dist error term\n",
    "    obs_t = pm.Normal('obs_t', mu=mu_t, sigma=sigma_t,  observed = Temp_, dims='alt_lat_lon_time')\n",
    "    obs_p = pm.Normal('obs_p', mu=mu_p, sigma=sigma_p, observed = Pres_, dims='alt_lat_lon_time')\n",
    "    \n",
    "print(pm.str_for_model(thermal_pres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(thermal_pres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the priors selected and their match to the observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with thermal_pres:\n",
    "    idata = pm.sample_prior_predictive(1000)\n",
    "az.plot_ppc(idata, group='prior', kind='cumulative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the generated data to the prior on temperature\n",
    "(idata.prior_predictive\n",
    " .obs_t.hvplot.kde(alpha=.5 ,\n",
    "                   label=\"Prior Predictive\") \n",
    "                   * \n",
    "                   xr_temp_pres.Temperature.pint.to('degC')\n",
    "                   .hvplot.kde(alpha=.5, \n",
    "                               label= \"Simulated Truth\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_class = idata.constant_data.Altitude_m //500 *500\n",
    "idata2 = idata.copy()\n",
    "idata.prior_predictive['Alt_Class'] = alt_class\n",
    "prior_temps_violin = (idata.prior_predictive\n",
    "                      .sortby('Alt_Class')\n",
    "                      .hvplot.violin(y = 'obs_t', \n",
    "                                     by='Alt_Class', \n",
    "                                     label='Assumed Prior',\n",
    "                                     violin_fill_alpha=0.5,\n",
    "                                     legend=True,\n",
    "                                     height=700,\n",
    "                                     width = 800))\n",
    "\n",
    "alt_class_true = xr_temp_pres.alt //500 * 500\n",
    "xr_temp_pres['Alt_Class_true'] = alt_class_true\n",
    "true_temps_violin = (xr_temp_pres[['Temperature','Alt_Class_true' ]]\n",
    "                     .pint.to({'Temperature':'degC'})\n",
    "                     .sortby('Alt_Class_true')\n",
    "                     .hvplot.violin(y='Temperature',\n",
    "                                    by='Alt_Class_true', \n",
    "                                    label='Sampled Truth',\n",
    "                                    violin_fill_alpha=0.5,\n",
    "                                    legend=True,\n",
    "                                    height=700,\n",
    "                                    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_temps_violin * true_temps_violin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MCMC bayesian sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with thermal_pres:\n",
    "    idata.extend(pm.sample(1000, tune=1000, chains = 4, cores=1))\n",
    "    # pymc sample posterior predictive check\n",
    "    pm.sample_posterior_predictive(idata, extend_inferencedata=True)\n",
    "    az.plot_ppc(idata, group='posterior', kind='cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As i am going to be messing with coordinates and attributes, i am going to make a copy of the data\n",
    "idata2 = idata.copy()\n",
    "idata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"plot.backend\"] = \"matplotlib\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctsignsize_mean_tempC_Km= -mean_tempC_Km*1000\n",
    "az.plot_trace(idata2,)\n",
    "#TODO: fix lines\n",
    "'''az.plot_trace(idata2, lines = (('Alt_effect_temp_Km', {},[correctsignsize_mean_tempC_Km]),\n",
    "                              #('Lat_effect_temp',{}, lat_inc_slope  ),\n",
    "                              #('lon_effect_temp',{}, lon_inc_mu  ), ))\n",
    "                              #('Lat_effect_temp',{}, lat_inc_slope / xr_traj_env_time_scaled.attrs['sdz_lat_spread'] ),\n",
    "                              #('lon_effect_temp',{}, lon_inc_mu / xr_traj_env_time_scaled.attrs['sdz_lon_spread'] ), ))\n",
    "                              ('Lat_effect_temp',{}, lat_inc_slope  * xr_traj_env_time.attrs['sdz_lat_spread'] ),  \n",
    "                              ('lon_effect_temp',{}, lon_inc_mu * xr_traj_env_time.attrs['sdz_lon_spread'] ), ))'''\n",
    "\n",
    "plt.subplots_adjust (hspace=0.4)#, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortby_alt = xr.DataArray(idata2.constant_data.Altitude_m.values,\n",
    "                                              coords={'alt_lat_lon_time':idata2.constant_data.alt_lat_lon_time.values})\n",
    "idata2 = idata2.map(lambda ds, **kwarg: ds.sortby(**kwarg), groups= [\"~sample_stats\"],variables=sortby_alt, ascending=False)\n",
    "idata2 = idata2.map(lambda ds, **kwarg: ds.assign_coords(**kwarg), \n",
    "           groups=['prior_predictive', 'posterior_predictive', 'observed_data'], \n",
    "           Altitude_m=(['alt_lat_lon_time'], idata2.constant_data.Altitude_m.values))\n",
    "\n",
    "idx_sortby_alt = idata2.constant_data.alt_lat_lon_time.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata2.constant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xarray filter by values - used in grouping graphs\n",
    "lat_min = idata2.constant_data.Latitude.min()\n",
    "lat_max = idata2.constant_data.Latitude.max()\n",
    "lon_min = idata2.constant_data.lonitude.min()\n",
    "lon_max = idata2.constant_data.lonitude.max()\n",
    "lat_mid = (lat_min + lat_max)/2\n",
    "lon_mid = (lon_min + lon_max)/2\n",
    "\n",
    "idx_north = idata2.constant_data.where(idata2.constant_data.Latitude>lat_mid, drop=True).alt_lat_lon_time.values\n",
    "idx_south = idata2.constant_data.where(idata2.constant_data.Latitude<lat_mid, drop=True).alt_lat_lon_time.values\n",
    "idx_east = idata2.constant_data.where(idata2.constant_data.lonitude>lon_mid, drop=True).alt_lat_lon_time.values\n",
    "idx_west = idata2.constant_data.where(idata2.constant_data.lonitude<lon_mid, drop=True).alt_lat_lon_time.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating class for labeling the altitude instead of variable index\n",
    "class DimCoordLabeller_alt(azl.BaseLabeller):\n",
    "    \"\"\"WIP.\"\"\"\n",
    "    def __init__(self, coords):\n",
    "        self.coords_ds = xr.Dataset(coords)\n",
    "        display(self.coords_ds)\n",
    "\n",
    "    def dim_coord_to_str(self, dim, coord_val, coord_idx):\n",
    "        \"\"\"WIP.\"\"\"#format decimals in f statement\n",
    "        temp =  self.coords_ds.sel(pointwise_sel=coord_val).items()\n",
    "        temp = [(v.values) for _,v in temp][0]\n",
    "        return f\"{temp:.2f}\" \n",
    "    \n",
    "coords = {\n",
    "    'alt_lat_lon_time': xr.DataArray(\n",
    "        idata2.constant_data.Altitude_m.values, \n",
    "        dims=['pointwise_sel'],coords={'pointwise_sel': idata2.constant_data.alt_lat_lon_time.values}\n",
    "    )\n",
    "}        \n",
    "labeller = DimCoordLabeller_alt(coords=coords)\n",
    "display(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figures with lat in coulmns and lonin rows\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "for i, ((N_S_label,N_S_idx), (E_W_label,E_W_idx)) in enumerate([[i,j] \n",
    "                                  for i in [('North',idx_north),('South',idx_south)] \n",
    "                                  for j in [('West',idx_west), ('East',idx_east)]]):\n",
    "    print(N_S_label,E_W_label)\n",
    "    ax[i].set_title(f'Lat: {N_S_label} lon: {E_W_label}')\n",
    "    idx = np.intersect1d(N_S_idx,E_W_idx)\n",
    "    az.plot_forest(idata2.sel(alt_lat_lon_time=[x for x in idx_sortby_alt\n",
    "                                                 if np.any(np.isin(idx,x))]),\n",
    "                   var_names=['mu_t'],\n",
    "                   kind='ridgeplot', \n",
    "                   combined=True, ax= ax[i],\n",
    "                   labeller=labeller,\n",
    "                   backend='matplotlib'\n",
    "                   )\n",
    "    #align the y axis\n",
    "    #ax[i].set_ylim(0, 10000)\n",
    "    ax[i].set_xlim(-50, 30)\n",
    "    ax[i].grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "az.plot_forest(idata2.sel( alt_lat_lon_time=idx_sortby_alt), var_names=['mu_t'],kind='ridgeplot', combined=True,labeller=labeller, backend='matplotlib')\n",
    "az.plot_forest(idata2.sel( alt_lat_lon_time=idx_sortby_alt), var_names=['mu_p'],kind='ridgeplot', combined=True,labeller=labeller)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_pred_Alt = idata2.map( lambda ds, **kwarg: \n",
    "                                   ds.swap_dims(**kwarg).drop('alt_lat_lon_time'),#.drop_indexes('Altitude_m'), \n",
    "                                   groups=['observed','predictive'], filter_groups='like', \n",
    "                                   alt_lat_lon_time='Altitude_m')\n",
    "group_alt_by = 2000\n",
    "idata_pred_Alt = idata_pred_Alt.map(lambda ds: ds.assign_coords(Altitude_grpd = ds.Altitude_m // group_alt_by *group_alt_by\n",
    "                                                                ).swap_dims({'Altitude_m':'Altitude_grpd'}\n",
    "                                                                            ).drop('Altitude_m'),\n",
    "                                                                            groups=['observed','predictive'], \n",
    "                                                                            filter_groups='like')\n",
    "\n",
    "#display(idata_pred_Alt)\n",
    "az.plot_dist_comparison(idata_pred_Alt, \n",
    "                        kind='observed', \n",
    "                        #labeller=labeller, \n",
    "                        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_dist_comparison(idata_pred_Alt, \n",
    "                        kind='observed', \n",
    "                        var_names=['obs_p']\n",
    "                        #labeller=labeller, \n",
    "                        )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save off model and trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save off pymc model\n",
    "def save_pymc_trace( trace=None, xr_data_source=None, filename='pymc_meodel', multi_index_to_reset =None):\n",
    "    trace_copy = trace.copy()\n",
    "    if xr_data_source:\n",
    "        if multi_index_to_reset:\n",
    "            print('adding this', xr_data_source.reset_index(multi_index_to_reset))\n",
    "            trace_copy.add_groups({'data_source':xr_data_source.reset_index(multi_index_to_reset)})\n",
    "        else:\n",
    "            trace_copy.add_groups({'data_source':xr_data_source})\n",
    "\n",
    "    trace_copy.to_netcdf(f'{filename}.nc')#to_zarr(filename)#\n",
    "        \n",
    "    #just rerun the model with no observed data\n",
    "    #with open(filename, 'wb') as buff:\n",
    "    #    pickle.dump({'model':model}, buff)\n",
    "# open pymc model and inference object\n",
    "def open_pymc_trace(filename='pymc_meodel'):\n",
    "    temp_idata = az.from_netcdf(f'{filename}.nc')#az.InferenceData.from_zarr(filename)#\n",
    "    \n",
    "    return temp_idata  #data['model'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with thermal_pres:\n",
    "    #save_pymc_trace(trace=idata2, xr_data_source =xr_traj_env_time , filename='thermal_pres', multi_index_to_reset='time')\n",
    "    save_pymc_trace(trace=idata2 , filename='thermal_pres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"data.load\"] = \"eager\"\n",
    "idata3 = open_pymc_trace(filename='thermal_pres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Counterfactual (what-if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams[\"plot.backend\"] = \"bokeh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lat and lonto the normalized transform (does it inplace in the new dataset)\n",
    "def investigate_dic(lat = [100, 100, 100, 100], lon= [250, 100, 250, 100], alt = [5, 5, 20000, 20000]):\n",
    "    investigate_lat_lon= xr.Dataset(data_vars={\n",
    "    'lat': lat,\n",
    "    'lon': lon,\n",
    "    'Altitude_m': alt,\n",
    "    'Temperature_Samples': [0, 0, 0,0],\n",
    "    'Pressure_Samples' :[0,0,0,0],\n",
    "    })\n",
    "        \n",
    "    return investigate_lat_lon\n",
    "\n",
    "investigate_lat_lon= investigate_dic()\n",
    "\n",
    "def make_temp_prediction(investigate_lat_lon, trace=idata2):\n",
    "    convert_normalization(xr_old= xr_traj_env_time,xr_new = investigate_lat_lon)\n",
    "\n",
    "    new_length = len(investigate_lat_lon.Temperature_Samples.values)\n",
    "    new_coord_values = (trace.constant_data.alt_lat_lon_time.values.max() +1) + np_arange(new_length)\n",
    "\n",
    "    with thermal_pres:\n",
    "        thermal_pres.set_dim(name='alt_lat_lon_time', \n",
    "                         new_length=new_length,\n",
    "                         coord_values=new_coord_values)\n",
    "    \n",
    "    with thermal_pres:\n",
    "    # do-operator\n",
    "        pm.set_data({'Altitude_m': investigate_lat_lon.Altitude_m.values,\n",
    "                 'Latitude': investigate_lat_lon.lat_norm.values,#investigate_lat_lon.lat_norm.values,\n",
    "                 'lonitude': investigate_lat_lon.lon_norm.values,\n",
    "                 'Temperature_Samples': investigate_lat_lon.Temperature_Samples.values,\n",
    "                 'Pressure_Samples' : investigate_lat_lon.Pressure_Samples.values,\n",
    "                 })\n",
    "    \n",
    "    # sample from this out of sample posterior predictive distribution\n",
    "        counterfactual = pm.sample_posterior_predictive(trace, var_names=[\"obs_t\"], predictions=True, progressbar=False)\n",
    "    counterfactual.predictions\n",
    "# make seaborn violin plots alonalt_lat_lon_time dimension from counterfactual xarray dataset\n",
    "\n",
    "\n",
    "    counterfactual.predictions_constant_data['lonitude'] = revert_normalization( counterfactual.predictions_constant_data.lonitude, \n",
    "                     revert_min=xr_traj_env_time.attrs['sdz_lon_min'], \n",
    "                     revert_spread=xr_traj_env_time.attrs['sdz_lon_spread'])\n",
    "    counterfactual.predictions_constant_data['Latitude'] = revert_normalization( counterfactual.predictions_constant_data.Latitude,\n",
    "                        revert_min=xr_traj_env_time.attrs['sdz_lat_min'],\n",
    "                        revert_spread=xr_traj_env_time.attrs['sdz_lat_spread'])\n",
    "    counterfactual.predictions=counterfactual.predictions.assign_coords(counterfactual.predictions_constant_data[['Latitude', 'lonitude', 'Altitude_m']])\n",
    "                            \n",
    "    return counterfactual\n",
    "\n",
    "counterfactual = make_temp_prediction(investigate_lat_lon)\n",
    "\n",
    "sns.violinplot(data=counterfactual.predictions.assign_coords(\n",
    "    counterfactual.predictions_constant_data[['Latitude', 'lonitude', 'Altitude_m']]).\n",
    "    to_dataframe().\n",
    "    reset_index(),\n",
    "                x='Altitude_m', y='obs_t', hue='lonitude')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code creates a panel that users can interact with to compare the temperature distributions at two sets of lat, lon, and altitude values.  The code uses the hvplot.violin method to create the distributions.\n",
    "pn.extension(sizing_mode = 'stretch_width', template='fast')\n",
    "\n",
    "slider_lat = pn.widgets.IntSlider(name='lat', start=0, end=200, step=1, value=50) # lat slider\n",
    "slider_lon= pn.widgets.IntSlider(name='lon', start=0, end=200, step=1, value=50) # lonslider\n",
    "slider_alt = pn.widgets.IntSlider(name='alt', start=0, end=20_000, step=500, value=500) # alt slider\n",
    "\n",
    "# second set for comparison\n",
    "slider_lat2 = pn.widgets.IntSlider(name='lat', start=0, end=200, step=1, value=50) # lat slider\n",
    "slider_lon2 = pn.widgets.IntSlider(name='lon', start=0, end=200, step=1, value=50) # lonslider\n",
    "slider_alt2 = pn.widgets.IntSlider(name='alt', start=0, end=20_000, step=500, value=500) # alt slider\n",
    "\n",
    "no_slider = [0]\n",
    "\n",
    "#plot_prediction takes in the coordinates of a point, and the number of samples to take from the distribution. It then plots the distribution of temperature at that point.\n",
    "#az.plot_violin\n",
    "def plot_prediction(slider_lat=50, slider_lon=50, slider_alt=500, no_slider=[0], var_names=\"obs_t\"):\n",
    "    \n",
    "    return make_temp_prediction(xr.Dataset(data_vars={\n",
    "    'lat': [slider_lat],\n",
    "    'lon': [slider_lon],\n",
    "    'Altitude_m': [slider_alt],\n",
    "    'Temperature_Samples': no_slider,\n",
    "    'Pressure_Samples' :no_slider,\n",
    "    })\n",
    "    ).predictions.swap_dims({'alt_lat_lon_time':'Altitude_m'}).hvplot.violin(y='obs_t',ylabel='Temperature (degC)',\n",
    "                 legend=False, title=f'Temperature Distribution at {slider_lat} lat, {slider_lon} lon, {slider_alt} alt',\n",
    "                 width=500, height=500, padding=0.4, shared_axes=True)\n",
    "\n",
    "def plot_prediction2(slider_lat=50, slider_lon=50, slider_alt=500,\n",
    "                     slider_lat2 = slider_lat2, slider_lon2= slider_lon2, slider_alt2=slider_alt2,\n",
    "                       no_slider=[0], var_names=\"obs_t\"):\n",
    "    both = plot_prediction(slider_lat=slider_lat, \n",
    "                           slider_lon=slider_lon, \n",
    "                           slider_alt=slider_alt) + plot_prediction(slider_lat=slider_lat2,\n",
    "                                                                    slider_lon=slider_lon2, \n",
    "                                                                    slider_alt=slider_alt2)\n",
    "    return both\n",
    "     \n",
    "    \n",
    "    \n",
    "\n",
    "pre_plot = plot_prediction()\n",
    "\n",
    "display_pn = pn.bind(plot_prediction2,\n",
    "                     slider_lat=slider_lat, \n",
    "                     slider_lon=slider_lon, \n",
    "                     slider_alt=slider_alt,\n",
    "                     slider_lat2=slider_lat2, \n",
    "                     slider_lon2=slider_lon2, \n",
    "                     slider_alt2=slider_alt2)\n",
    "#display_pn2 = pn.bind(plot_prediction,slider_lat=slider_lat2, slider_lon=slider_lon2, slider_alt=slider_alt2)\n",
    "\n",
    "really_display_pn = pn.Column(pn.Row('##Interactive Temperature Comparison'),\n",
    "                              pn.Row(pn.Column(slider_lat, slider_lon, slider_alt),pn.Column(slider_lat2, slider_lon2, slider_alt2)),\n",
    "                              pn.Row(display_pn))\n",
    "#sync the y axis of both graphs\n",
    "#really_display_pn[2][0][0].link(really_display_pn[2][1][0], bidirectional=True, links={'ylim':'ylim'}) \n",
    "really_display_pn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
